{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecc1973c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\shiva shankar\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\shiva shankar\\anaconda3\\lib\\site-packages (from gensim) (1.21.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\shiva shankar\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\shiva shankar\\anaconda3\\lib\\site-packages (from gensim) (1.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4295b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "def read_file(file_name):\n",
    "  with open(file_name, 'r+', encoding='unicode_escape') as file:\n",
    "    file_text = file.read()\n",
    "  return file_text\n",
    "\n",
    "def process_speeches(speeches):\n",
    "  word_tokenized_speeches = list()\n",
    "  for speech in speeches:\n",
    "    sentence_tokenizer = PunktSentenceTokenizer()\n",
    "    sentence_tokenized_speech = sentence_tokenizer.tokenize(speech)\n",
    "    word_tokenized_sentences = list()\n",
    "    for sentence in sentence_tokenized_speech:\n",
    "      word_tokenized_sentence = [word.lower().strip('.').strip('?').strip('!') for word in sentence.replace(\",\",\"\").replace(\"-\",\" \").replace(\":\",\"\").split()]\n",
    "      word_tokenized_sentences.append(word_tokenized_sentence)\n",
    "    word_tokenized_speeches.append(word_tokenized_sentences)\n",
    "  return word_tokenized_speeches\n",
    "\n",
    "def merge_speeches(speeches):\n",
    "  all_sentences = list()\n",
    "  for speech in speeches:\n",
    "    for sentence in speech:\n",
    "      all_sentences.append(sentence)\n",
    "  return all_sentences\n",
    "\n",
    "def get_president_sentences(president):\n",
    "  files = sorted([file for file in os.listdir() if president.lower() in file.lower()])\n",
    "  speeches = [read_file(file) for file in files]\n",
    "  processed_speeches = process_speeches(speeches)\n",
    "  all_sentences = merge_speeches(processed_speeches)\n",
    "  return all_sentences\n",
    "\n",
    "def get_presidents_sentences(presidents):\n",
    "  all_sentences = list()\n",
    "  for president in presidents:\n",
    "    files = sorted([file for file in os.listdir() if president.lower() in file.lower()])\n",
    "    speeches = [read_file(file) for file in files]\n",
    "    processed_speeches = process_speeches(speeches)\n",
    "    all_prez_sentences = merge_speeches(processed_speeches)\n",
    "    all_sentences.extend(all_prez_sentences)\n",
    "  return all_sentences\n",
    "\n",
    "def most_frequent_words(list_of_sentences):\n",
    "  all_words = [word for sentence in list_of_sentences for word in sentence]\n",
    "  SW_removed = []\n",
    "  for word in all_words:\n",
    "    if word not in stop_words:\n",
    "        SW_removed.append(word)\n",
    "  return Counter(SW_removed).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c61c1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('economic', 0.9637851715087891), ('human', 0.9571189284324646), ('independence', 0.9544987678527832), ('security', 0.9542917013168335), ('individual', 0.9540867209434509), ('condition', 0.9540834426879883), ('parties', 0.9539456963539124), ('domestic', 0.9529170989990234), ('business', 0.9525957703590393), ('growth', 0.9521768093109131), ('life', 0.9515205025672913), ('wealth', 0.9504293203353882), ('prosperity', 0.9482309222221375), ('dignity', 0.9481265544891357), ('progress', 0.9478520750999451), ('department', 0.9472221732139587), ('race', 0.9469015598297119), ('influence', 0.9467835426330566), ('maintenance', 0.9466908574104309), ('order', 0.9464203715324402)]\n",
      "[('government', 0.9971845149993896), ('from', 0.9971229434013367), ('that', 0.9970899820327759), ('on', 0.997053325176239), ('i', 0.9969252943992615), ('our', 0.9969114661216736), ('but', 0.9969032406806946), ('so', 0.9968989491462708), ('an', 0.9968894720077515), ('shall', 0.9968706369400024), ('and', 0.996863603591919), ('has', 0.9968251585960388), ('men', 0.9968247413635254), ('all', 0.9967839121818542), ('or', 0.9967703819274902), ('we', 0.9967576861381531), ('the', 0.9967336058616638), ('because', 0.9967265725135803), ('may', 0.996699333190918), ('at', 0.9966979622840881)]\n",
      "[('life', 6), ('necessary', 6), ('act', 6), ('many', 6), ('future', 6), ('mind', 6), ('executive', 6), ('circumstances', 6), ('objects', 6), ('given', 6), ('place', 6), ('interests', 6), ('american', 6), ('judgment', 6), ('exercise', 6), ('harmony', 6), ('therefore', 6), ('possible', 6), ('favor', 6), ('form', 6), ('express', 6), ('friends', 6), ('intercourse', 6), ('change', 6), ('know', 6), ('fear', 6), ('vital', 6), ('press', 6), ('better', 6), ('foreign', 6), ('ever', 6), ('whether', 6), ('object', 6), ('always', 6), ('day', 5), ('hand', 5), ('trust', 5), ('civil', 5), ('official', 5), ('success', 5), ('sentiments', 5), ('affairs', 5), ('revolution', 5), ('join', 5), ('meet', 5), ('powers', 5), ('particular', 5), ('honest', 5), ('republican', 5), ('experiment', 5), ('instead', 5), ('perfect', 5), ('presence', 5), ('found', 5), ('industry', 5), ('beyond', 5), ('indeed', 5), ('provided', 5), ('wisdom', 5), ('according', 5)]\n",
      "[('without', 0.9985358119010925), ('shall', 0.9984955191612244), ('nations', 0.9984048008918762), ('are', 0.9983391761779785), ('nation', 0.9983386993408203), ('still', 0.9982983469963074), ('present', 0.9982866048812866), ('these', 0.9982513785362244), ('under', 0.9981901049613953), ('so', 0.9981874227523804), ('same', 0.9981865882873535), ('over', 0.9981809258460999), ('itself', 0.998144268989563), ('less', 0.9981433749198914), ('rights', 0.9981335997581482), ('time', 0.9981328248977661), ('right', 0.9981248378753662), ('before', 0.9981244802474976), ('we', 0.9981194734573364), ('may', 0.998117983341217)]\n",
      "[('are', 0.998603105545044), ('was', 0.9985123872756958), ('an', 0.99848473072052), ('or', 0.9984622001647949), ('his', 0.9984570145606995), ('through', 0.9984146952629089), ('rights', 0.9984083771705627), ('may', 0.9983721375465393), ('our', 0.9983646869659424), ('man', 0.9983633160591125), ('still', 0.9983447194099426), ('right', 0.9983353018760681), ('who', 0.998332679271698), ('all', 0.9983319640159607), ('nation', 0.9983245134353638), ('great', 0.9983187913894653), ('time', 0.9983172416687012), ('without', 0.9983083605766296), ('best', 0.9982943534851074), ('these', 0.9982877969741821)]\n",
      "[('can', 0.9983124732971191), ('hope', 0.9982064366340637), ('when', 0.9981889128684998), ('at', 0.9981761574745178), ('again', 0.9981492161750793), ('what', 0.9981400966644287), ('shall', 0.9981250166893005), ('ever', 0.9981085062026978), ('years', 0.9980710744857788), ('been', 0.9980412721633911), ('man', 0.99803227186203), ('i', 0.9980224370956421), ('some', 0.9980186223983765), ('made', 0.9980126023292542), ('was', 0.9979994893074036), ('every', 0.9979894757270813), ('laws', 0.9979879856109619), ('without', 0.9979766011238098), ('under', 0.9979720711708069), ('present', 0.9979568123817444)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gensim\n",
    "import spacy\n",
    "from gensim import models\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#from president_helper import read_file, process_speeches, merge_speeches, get_president_sentences, get_presidents_sentences, most_frequent_words\n",
    "\n",
    "# get list of all speech files\n",
    "files = sorted([file for file in os.listdir() if file[-4:] == '.txt'])\n",
    "#print(files)\n",
    "# read each speech file\n",
    "speeches = [read_file(item) for item in files]\n",
    "#print(speeches[0])\n",
    "\n",
    "# preprocess each speech\n",
    "processed_speeches = process_speeches(speeches) \n",
    "#print(processed_speeches[0][0][:6])\n",
    "# merge speeches\n",
    "all_sentences = merge_speeches(processed_speeches)\n",
    "\n",
    "\n",
    "# view most frequently used words\n",
    "most_freq_words = most_frequent_words(all_sentences)\n",
    "#print(most_freq_words)\n",
    "\n",
    "# create gensim model of all speeches\n",
    "all_prez_embeddings =  gensim.models.Word2Vec(all_sentences ,min_count=1, vector_size = 96 , window=5,workers=2, sg=1)\n",
    "similar_to_freedom = all_prez_embeddings.wv.most_similar(\"freedom\", topn=20 ) \n",
    "print(similar_to_freedom)\n",
    "\n",
    "# view words similar to freedom\n",
    "#print(similar_to_freedom)\n",
    "#print(most_freq_words[15])\n",
    "imilar_to_human = all_prez_embeddings.wv.most_similar(\"human\", topn=20)\n",
    "#print(imilar_to_human)\n",
    "# get President Roosevelt sentences\n",
    "\n",
    "roosevelt_sentences = get_president_sentences(\"Roosevelt\")\n",
    "\n",
    "# view most frequently used words of Roosevelt\n",
    "\n",
    "roosevelt_most_freq_words = most_frequent_words(roosevelt_sentences)\n",
    "#print(roosevelt_most_freq_words)\n",
    "\n",
    "# create gensim model for Roosevelt\n",
    "roosevelt_embeddings = gensim.models.Word2Vec(roosevelt_sentences, vector_size=96, window=5, min_count=1, workers=2, sg=1)\n",
    "# view words similar to freedom for Roosevelt\n",
    "roosevelt_similar_to_freedom = roosevelt_embeddings.wv.most_similar(\"freedom\", topn=20)\n",
    "print(roosevelt_similar_to_freedom)\n",
    "\n",
    "# get sentences of multiple presidents\n",
    "rushmore_prez_sentences = get_presidents_sentences([\"washington\",\"jefferson\",\"lincoln\",\"Kennedy\"])\n",
    "\n",
    "\n",
    "# view most frequently used words of presidents\n",
    "rushmore_most_freq_words = most_frequent_words(rushmore_prez_sentences)\n",
    "print(rushmore_most_freq_words[120: 180])\n",
    "\n",
    "# create gensim model for the presidents\n",
    "rushmore_embeddings = gensim.models.Word2Vec(rushmore_prez_sentences, vector_size=96, window=5, min_count=1, workers=2, sg=1)\n",
    "\n",
    "\n",
    "# view words similar to freedom for presidents\n",
    "rushmore_similar_to_freedom = rushmore_embeddings.wv.most_similar(\"freedom\", topn=20)\n",
    "print(rushmore_similar_to_freedom)\n",
    "# what words the P's spoke on rushmore similar to [\"confidence, 'justice\"]\n",
    "rushmore_similar_justice= rushmore_embeddings.wv.most_similar(\"justice\", topn=20)\n",
    "rushmore_similar_confidence= rushmore_embeddings.wv.most_similar(\"confidence\", topn=20)\n",
    "\n",
    "print(rushmore_similar_justice)\n",
    "print(rushmore_similar_confidence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
